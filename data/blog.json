[
  {
    "title": "PyBuddy: A Local-First LLM Coding Assistant for Everyone",
    "date": "2025-09-09",
    "description": "A Small Language Model based Python Coding Assistant for Low Resource Devices.",
    "tags": ["llm", "on-device inference", "code-assistant"],
    "readTime": "6 min read",
    "slug": "pybuddy-local-ai-code-assistant"
  },
  {
    "title": "Turn Your Android Device into a Remote Linux Server in 30 Minutes",
    "date": "2025-08-25",
    "description": "Have you ever thought about turning your Android phone into a pocket Linux server without root? A server thatâ€™s accessible from anywhere in the world and can run your services 24/7 without any cost.",
    "tags": ["pocket-server", "ssh", "mesh-network", "linux"],
    "readTime": "6 min read",
    "slug": "turn-android-device-into-remote-linux-server-in-30-minutes"
  },
  {
    "title": "Hacks to use Google Colab Free GPU on Local VS-code for Inference",
    "date": "2025-01-25",
    "description": "Use Google Colab's free 15GB T4 GPU for inference through your local machine.",
    "tags": ["llm", "free-gpu", "hybrid-inference"],
    "readTime": "13 min read",
    "slug": "google-colab-free-gpu-on-local-device-for-inference"
  },
  {
    "title": "EXAONE-3.5-2.4B: A Ultra-lightweight but High Performing LLM on Just 6GB GPU",
    "date": "2025-01-04",
    "description": "An ultra-lightweight opensource model for low resource use",
    "tags": ["llm", "consumer-device", "inference"],
    "readTime": "3 min read",
    "slug": "exaone-3-5-2-4b-pre-trained"
  }
]